{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f98c53a2",
   "metadata": {},
   "source": [
    "- 本章将介绍不同集群管理器的根本区别\n",
    "- 目前Spark有三个官方支持的集群管理器\n",
    "    - Standalone模式\n",
    "    - Hadoop YARN\n",
    "    - Apache Mesos\n",
    "- 这些集群管理器维护一组机器用于部署你的Spark应用程序|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e5fcb6",
   "metadata": {},
   "source": [
    "<h4>在哪里部署Spark集群</h4>\n",
    "\n",
    "- 有两个选择，部署在本地集群或公共云中"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7feeb2",
   "metadata": {},
   "source": [
    "<h4>本地部署集群</h4>\n",
    "\n",
    "- 对于有自己数据中心的大企业或组织，应该将Spark部署到本地数据中心\n",
    "- 本地集群允许你完全控制所用硬件设备，可以针对特定的工作负载来优化性能\n",
    "- 但是，如果采用本地部署，集群的大小往往是固定的，数据分析作业的资源需求往往是有弹性的\n",
    "- 集群太小，很难执行偶尔需要的任务量异常繁重的分析查询或训练工作\n",
    "- 集群规模太大，将会有资源闲置和浪费资源的情况发生"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4721a016",
   "metadata": {},
   "source": [
    "<h4>在公有云上的Spark</h4>\n",
    "\n",
    "- 弹性地申请和释放计算资源\n",
    "- 公有云会为客户提供配置好的Hadoop集群，提供HDFS存储和Apache Spark计算框架\n",
    "- 建议使用与计算集群分离的存储系统，并为每个Spark作业动态绑定存储系统"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e35a40f",
   "metadata": {},
   "source": [
    "<h4>集群管理器</h4>\n",
    "\n",
    "- 除非使用高级托管服务，否则就需要为Spark选择集群管理器\n",
    "- 目前Spark支持三种集群管理器：Standalone集群, Hadoop YARN和Mesos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95ffbbc",
   "metadata": {},
   "source": [
    "<h3>Standalone集群管理器</h3>\n",
    "\n",
    "- 专门为Apache Spark工作负载构建的轻量级平台\n",
    "- Standalone集群管理器允许你在同一个物理集群上运行多个Spark应用程序\n",
    "- 其主要缺点是它的功能相对其它集群管理器来说比较有限\n",
    "- 特别是集群只能运行Spark作业"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0759d9",
   "metadata": {},
   "source": [
    "<h4>启动Standalone集群</h4>\n",
    "\n",
    "- 首先启动集群包含的物理节点，确保节点之间可以通过网络互相通信\n",
    "- 在所有节点上安装正确版本的Spark软件\n",
    "- 启动集群的方式有两种：手动或使用内置的启动脚本"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc67507a",
   "metadata": {},
   "source": [
    "<h4>手动启动一个集群</h4>\n",
    "\n",
    "- 第一步是使用以下命令在某台机器上启动主进程\n",
    "    - $SPARK_HOME/sbin/start-master.sh\n",
    "- 运行完这个命令后，集群管理器主进程将在该机器上启动\n",
    "- 一旦启动成功，master主机就会在命令行打印出一个URL，即spark://HOST:PORT\n",
    "- 你可以在应用程序初始化时，将此URL用作SparkSession的主要参数\n",
    "- 还可以在master节点的web用户界面上找到此URL，默认情况下界面地址是 http://master-ip-address:8080"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8dc2b5",
   "metadata": {},
   "source": [
    "- 然后启动工作节点，注意，master节点必须在网络上可访问，并且master节点的指定端口必须打开\n",
    "- 来到一台计算节点上，同样适用master启动时给的URL\n",
    "    - $SPARK_HOME/sbin/start-slave.sh \\<master-spark-URL>\n",
    "- 以上就成功构建了一个包括一个master节点和一个worker节点的Spark集群"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246fb964",
   "metadata": {},
   "source": [
    "<h4>集群启动脚本</h4>\n",
    "\n",
    "- 首先需要在Spark目录中创建一个名为conf/slaves的文件\n",
    "- 该文件需要包含启动worker进程的所有计算机主机名\n",
    "- 如果文件不存在，那么集群会以本地模式启动\n",
    "- 实际启动集群时，master节点将通过Secure Shell（SSH）访问每个worker节点，默认情况下需要配置无密码设置SSH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0658650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"img/conf.png\", width=300>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src=\"img/conf.png\", width=300>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developmental-mongolia",
   "metadata": {},
   "source": [
    "<h4>以下是启动或停止的shell脚本</h4>\n",
    "\n",
    "- 全部可以在$SPARK_HOME/sbin中找到\n",
    "- \\$ SPARK_HOME/sbin/start-master.sh\n",
    "    - 在执行脚本的机器上启动master实例\n",
    "- \\$ SPARK_HOME/sbin/start-slaves.sh\n",
    "    - 在config/slaves文件中指定的每台机器上启动一个slave实例\n",
    "- \\$ SPARK_HOME/sbin/start-slave.sh\n",
    "    - 在执行脚本的机器上启动一个slave实例\n",
    "- \\$ SPARK_HOME/sbin/start-all.sh\n",
    "    - 按照配置文件，在指定机器上启动一个master实例和在指定的多台机器上启动多个slave实例"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visible-malawi",
   "metadata": {},
   "source": [
    "<h4>提交应用程序</h4>\n",
    "\n",
    "\n",
    "- 对spark-submit的--master参数指定master节点的URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "certain-pattern",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"img/standalone.png\", width=600>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src=\"img/standalone.png\", width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatal-fountain",
   "metadata": {},
   "source": [
    "<h3>YARN集群管理器</h3>\n",
    "\n",
    "- 通过spark-submit命令行参数中将master节点指定为YARN\n",
    "- SPARK将使用环境变量 HADOOP_CONF_DIR 或 YARN_CONF_DIR 来查找YARN配置文件，将这些环境变量设置为Hadoop的安装目录"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beneficial-lawrence",
   "metadata": {},
   "source": [
    "<h4>Hadoop配置</h4>\n",
    "\n",
    "- 如果想使用Spark从HDFS进行读写，需要在classpath中包含两个Hadoop配置文件\n",
    "    - hdfs-site.xml（配置HDFS客户端）和 core-site.xml（设置默认的文件系统名称）\n",
    "    - 这些配置文件常见位置在/etc/hadoop/conf中\n",
    "- 为了让这些文件对Spark可见，请将 $SPARK_HOME/spark-env.sh 中的HADOOP_CONF_DIR设置为包含Hadoop的文件\n",
    "- 或者在启动应用程序时将其设置为环境变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "friendly-tribune",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noticed-consistency",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
