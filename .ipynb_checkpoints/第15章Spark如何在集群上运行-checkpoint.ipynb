{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f74b6adc",
   "metadata": {},
   "source": [
    "<h4>本章重点介绍Spark在集群上执行代码的全过程</h4>\n",
    "\n",
    "- Spark应用程序的体系结构和组件\n",
    "- Spark应用程序的生命周期\n",
    "- 重要的底层执行属性，例如流水线处理\n",
    "- 运行一个Spark应用程序都需要什么"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e2d8fd",
   "metadata": {},
   "source": [
    "<h4>Spark应用程序的体系结构</h4>\n",
    "\n",
    "- 首先细说下Spark应用程序模块"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9af09bd",
   "metadata": {},
   "source": [
    "<h4>Spark驱动器</h4>\n",
    "\n",
    "- Spark驱动器程序控制应用程序的进程，负责整个应用程序的执行并且维护着Spark集群的状态，即执行器的任务和状态\n",
    "- Spark驱动器必须与集群管理器交互才能获得物理资源，并启动执行器\n",
    "- 简而言之，Spark驱动器只是物理机器上的一个进程，负责维护集群上运行的应用程序状态"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b57e71",
   "metadata": {},
   "source": [
    "<h4>Spark执行器</h4>\n",
    "\n",
    "- Spark执行器也是一个进程，负责执行由Spark驱动器分配的任务\n",
    "- Spark执行器核心功能：运行驱动器分配的任务、报告成功或失败的状态和执行结果\n",
    "- 每个Spark应用程序都有自己的执行器进程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e6d75f",
   "metadata": {},
   "source": [
    "<h4>集群管理器</h4>\n",
    "\n",
    "- Spark驱动器和执行器依靠集群管理器联系在一起\n",
    "- 集群管理器有自己的集群驱动器和集群工作节点的抽象\n",
    "- 与Spark执行器、驱动器的区别在于集群管理器管理的<b>是物理机器而非进程</b>\n",
    "- 实际运行Spark应用程序时，我们从集群管理器中请求运行Spark驱动器的机器资源和Spark执行器的计算资源"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5054df3",
   "metadata": {},
   "source": [
    "<h4>Spark目前支持三个集群管理器</h4>\n",
    "\n",
    "- 内置独立集群管理器\n",
    "- Apache Mesos\n",
    "- Hadoop YARN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68490afc",
   "metadata": {},
   "source": [
    "- 在运行应用程序之前，需要选择执行模式，以确定计算资源的物理位置，常用的有以下三种\n",
    "    - 集群模式\n",
    "    - 客户端模式\n",
    "    - 本地模式"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e20fcdf",
   "metadata": {},
   "source": [
    "<h4>集群模式</h4>\n",
    "\n",
    "- 将预编译的JAR包、Python脚本提交给集群管理器\n",
    "- 除了执行器进程外，集群管理器会在集群内的某个工作节点上启动驱动器进程\n",
    "- 这意味着集群管理器负责维护所有与Spark应用程序相关的进程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76356f7",
   "metadata": {},
   "source": [
    "<h4>客户端模式</h4>\n",
    "\n",
    "- 与集群模式几乎相同，只是Spark驱动器保留在提交应用程序的客户端机器中\n",
    "- 这些机器通常被称为网关机器（gateway machines）和边缘节点（edge nodes）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00b1be1",
   "metadata": {},
   "source": [
    "<h4>本地模式</h4>\n",
    "\n",
    "- 在一台机器上运行整个Spark应用程序\n",
    "- 通过单机的线程实现并行性"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbf03d9",
   "metadata": {},
   "source": [
    "<h4>Spark应用程序的生命周期（Spark外部）</h4>\n",
    "\n",
    "- 以下介绍Spark应用程序从初始化到退出的生命周期\n",
    "- 假设，我们使用集群模式，即由集群工作节点启动Spark驱动器和执行器\n",
    "- 假设该集群运行了四个节点，其中包括一个驱动节点和三个工作节点"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf54e68",
   "metadata": {},
   "source": [
    "1. 客户请求\n",
    "\n",
    "- 第一步是提交应用程序，应用程序通常是编译好的JAR包或者库\n",
    "- 首先向集群管理器的驱动节点发起请求，为Spark驱动器进程显式地请求资源\n",
    "- 集群管理器接受请求并将驱动器放到集群中的一个物理节点上\n",
    "- 之后提交应用程序的客户端退出，应用程序开始在集群上运行\n",
    "- 以下为需要运行的命令"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4795a9c0",
   "metadata": {},
   "source": [
    "./bin/spark-submit \\\n",
    "    --class \\<main-class> \\\\<br>\n",
    "    --master \\<master-url> \\\\<br>\n",
    "    --deploy-mode cluster \\\\<br>\n",
    "    --conf \\<key>=\\<value> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae65fdab",
   "metadata": {},
   "source": [
    "2. 启动\n",
    "\n",
    "- 现在驱动器已经被放到集群上了，它开始执行用户代码\n",
    "- 此代码必须包含一个初始化Spark集群（如驱动器和若干执行器）的SparkSession\n",
    "- SparkSession随后将于集群管理器的驱动节点通信，要求它在集群上启动Spark执行器\n",
    "- 集群管理器随后在集群工作节点上启动执行器\n",
    "- 执行器的数量及相关配置由用户通过最开始spark-submit调用中的命令行参数设置\n",
    "\n",
    "\n",
    "- 假如一切顺利，集群管理器会启动Spark执行器，并将程序执行位置等相关信息发送给Spark驱动器\n",
    "- 所有程序正确关联后，Spark集群构建完成"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3d6430",
   "metadata": {},
   "source": [
    "3. 执行\n",
    "\n",
    "- 自此，集群的驱动节点和工作节点相互通信、执行代码和移动数据\n",
    "- 驱动节点将任务安排到每个工作节点上\n",
    "- 每个工作节点回应给驱动节点这些任务的执行状态，回复启动成功或启动失败"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fb588a",
   "metadata": {},
   "source": [
    "4. 完成\n",
    "\n",
    "- Spark应用程序完成后，Spark驱动器会以成功或失败状态退出\n",
    "- 集群管理器会为该驱动器关闭集群中的执行器\n",
    "- 可以向集群管理器询问，Spark应用程序是成功退出还是失败退出"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stupid-offer",
   "metadata": {},
   "source": [
    "<h4>Spark应用程序的生命周期（Spark内部）</h4>\n",
    "\n",
    "- 每个应用程序由一个或多个Spark作业组成，这一系列作业是串行执行的\n",
    "- 除非使用多线程并行启动多个作业"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compressed-nerve",
   "metadata": {},
   "source": [
    "<h4>SparkSession</h4>\n",
    "\n",
    "- 任何Spark应用程序第一步都是创建一个SparkSession，交互模式中通常预先创建\n",
    "- 但在应用程序中需要自己创建\n",
    "- 以下是SparkSession的创建方法，构建器方法，该方法可以稳定实例化Spark和SQL Context\n",
    "- 创建SparkSession后，就可以访问和运行Spark代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dietary-apple",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"local\").appName(\"Word Count\")\\\n",
    "    .config(\"spark.some.config.option\", \"some-value\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optimum-utility",
   "metadata": {},
   "source": [
    "<h4>SparkContext</h4>\n",
    "\n",
    "- SparkSession中的SparkContext对象代表与Spark集群的连接\n",
    "- 可以通过它与一些Spark的低级API进行通信\n",
    "- 在早期的示例文档中，通常以变量sc存储\n",
    "- 通过SparkContext，可以创建RDD、累加器和广播变量\n",
    "- 如今的SparkSession = SparkContext + SQLContext\n",
    "- 需要注意的是，你应该永远不需要使用SQLContext，并尽量避免使用SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "republican-mobility",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sparkContext.parallelize(range(1, 21))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "empirical-majority",
   "metadata": {},
   "source": [
    "<h4>逻辑指令</h4>\n",
    "\n",
    "- Spark代码基本上由转换和动作组成\n",
    "- 以下首先使用一个简单的DataFrame执行三步\n",
    "    1. 重新分区\n",
    "    2. 执行逐个值的操作\n",
    "    3. 执行聚合操作并收集最终结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saving-virginia",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.range()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
