{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "peaceful-snake",
   "metadata": {},
   "source": [
    "<h4>什么是流处理？</h4>\n",
    "\n",
    "- 流处理是连续处理新到来的数据以更新计算结果的行为\n",
    "- 在流处理中，输入数据是无边界的，没有预定的开始或结束\n",
    "\n",
    "\n",
    "<h4>流处理与批处理的比较</h4>\n",
    "\n",
    "- 批处理（batch processing）是在固定大小数据集上进行计算的，这可能是数据仓库中的大规模数据集\n",
    "- 虽然流处理和批处理不同，但事件中经常需要一起使用\n",
    "    - 因为流式作业的输出通常是在批次处理作业中要查询的文件或数据表\n",
    "- 结构化流处理开发人员提出了连续应用程序（continuous application）的概念\n",
    "- 它把包括流处理、批处理和交互式作业等全部作用在同一数据集上的处理环节串联起来"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informational-myrtle",
   "metadata": {},
   "source": [
    "<h4>流处理应用场景</h4>\n",
    "\n",
    "- 通知和警报\n",
    "    - 给定一系列时间，如果发生某一件事或一系列特殊事件，则应触发通知或警报\n",
    "- 实时报告\n",
    "    - 运行实时查看的动态仪表盘\n",
    "- 增量ETL\n",
    "    - 最常见的流处理应用程序之一是减少公司在信息检索时必须忍受的延迟时间\n",
    "    - 把批处理任务用流处理方式执行\n",
    "    - Spark批处理任务通常用于抽取-转换-加载任务（ETL任务，Extract-Transform-Load），将原始数据转换为结构化格式以支持高效查询\n",
    "    - 使用结构化流处理可以在几秒内处理新数据\n",
    "- 实时数据更新提供实时服务\n",
    "    - 谷歌分析（Google Analytics）这样的web分析产品会持续跟踪每个网页的访问次数\n",
    "- 实时决策\n",
    "    - 分析新的输入，根据业务逻辑自动作出决策来应对新数据\n",
    "    - 比如银行希望自动验证客户信用卡上的新记录交易是否为一个可疑交易"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "characteristic-prairie",
   "metadata": {},
   "source": [
    "<h4>流处理的优点</h4>\n",
    "\n",
    "- 流处理系统将状态保存在内存中，可以降低延迟时间\n",
    "- 流处理在更新结果方面更高效，会自动进行增量计算"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "independent-progressive",
   "metadata": {},
   "source": [
    "<h4>流处理的挑战</h4>\n",
    "\n",
    "- 基于应用程序的时间戳处理无序数据，可能会受到延迟、重新传输的干扰\n",
    "- 维持大量状态\n",
    "- 支持高吞吐量\n",
    "- 处理负载不均衡和拖延者（straggler）\n",
    "- 快速响应时间\n",
    "- 与其他存储系统中的数据连接\n",
    "- 确定在新事件到达时如何更新输出\n",
    "- 在运行时更新应用程序的业务逻辑"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "completed-pastor",
   "metadata": {},
   "source": [
    "<h4>Spark的流处理API</h4>\n",
    "\n",
    "- Spark包含两种流处理API，早期的DStream API基于微批量处理模式，声明式API，不支持事件时间\n",
    "- 新的结构化流处理API添加了更高级别的优化、事件时间，并支持连续处理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expanded-crack",
   "metadata": {},
   "source": [
    "<h4>DStream API</h4>\n",
    "\n",
    "- 使用广泛的流处理引擎\n",
    "- DStream API有几个限制\n",
    "    - 完全基于Java/Python对象和函数，而不是DataFrame和Dataset中丰富的结构化表概念，不利于执行引擎优化\n",
    "    - DStream API纯粹基于处理时间（processing time），即流处理应用程序接受记录的时间\n",
    "    - 而非事件时间（event time），即事件插入记录中的时间戳来处理数据的概念\n",
    "    - DStream只能以微批量处理（Mirco-batch Processing）模式运行，而非连续处理（Continuous Processing）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "little-tuner",
   "metadata": {},
   "source": [
    "<h4>结构化流处理</h4>\n",
    "\n",
    "- 基于Spark结构化API的高级流处理API\n",
    "- 适用于运行结构化处理的所有环境\n",
    "- 与DStream一样，是基于高级操作的声明式API\n",
    "- 结构化流处理对事件时间有原生支持，并支持连续处理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "usual-wiring",
   "metadata": {},
   "source": [
    "<h4>接收器</h4>\n",
    "\n",
    "- 需要指定数据源来读取数据流，也需要指定接收器来设置流处理之后结果集的去处\n",
    "- 接收器（sink）和执行引擎还负责可靠地跟踪数据处理的进度"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "right-assist",
   "metadata": {},
   "source": [
    "<h4>输出模式</h4>\n",
    "\n",
    "- 定义Spark将数据以何种形式写入接收器\n",
    "- "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
